# from TTS.utils.synthesizer import Synthesizer
# import sounddevice as sd

# # ğŸ”§ Ø³Ø§Ø®Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÛŒ Ø³ÛŒÙ†ØªÛŒâ€ŒØ³Ø§ÛŒØ²Ø± Ø¨Ø§ Ù…Ø¯Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡
# synthesizer = Synthesizer(
#     tts_checkpoint="tts_models/models/tacotron2_ddc/tts-model_file.pth",
#     tts_config_path="tts_models/models/tacotron2_ddc/tts-config.json",
#     vocoder_checkpoint="tts_models/models/tacotron2_ddc/vocoder-model_file.pth.tar",
#     vocoder_config="tts_models/models/tacotron2_ddc/vocoder-config.json",
#     use_cuda=False
# )

# # ğŸ¤ Ø¬Ù…Ù„Ù‡ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
# text = "Hello sir. All systems are online."

# # ğŸ§ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§
# wav = synthesizer.tts(text)

# # ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ÙØ§ÛŒÙ„ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
# synthesizer.save_wav(wav, "jarvis_output.wav")

# # ğŸ”Š Ù¾Ø®Ø´ ØµØ¯Ø§
# sd.play(wav, 22050)
# sd.wait()
# import time

# import asyncio
# import edge_tts
# from playsound import playsound

# VOICE = "en-US-GuyNeural"
# OUTPUT_FILE = "output.mp3"

# loop = asyncio.get_event_loop()

# async def speak_text_async(text):
#     communicate = edge_tts.Communicate(text, VOICE)
#     await communicate.save(OUTPUT_FILE)
#     playsound(OUTPUT_FILE)


# def speak(text):
#     start = time.time()
#     asyncio.run(speak_text_async(text))
#     end = time.time()
#     print(f"SPEAK TOOK: {end - start:.2f} seconds")


# if __name__ == "__main__":
#     total_start = time.time()
#     speak("Hello, this is Richard speaking. I'm ready to serve you.")
#     print(f"TOTAL RESPONSE TIME: {time.time() - total_start:.2f} sec")


# import sounddevice as sd
# import vosk
# import queue
# import json

# model = vosk.Model("models/vosk-model-small-en-us-0.15")
# q = queue.Queue()

# def callback(indata, frames, time, status):
#     q.put(bytes(indata))

# samplerate = 16000
# with sd.RawInputStream(samplerate=samplerate, blocksize=8000, dtype='int16',
#                        channels=1, callback=callback):
#     print("Say something...")

#     rec = vosk.KaldiRecognizer(model, samplerate)
#     while True:
#         data = q.get()
#         if rec.AcceptWaveform(data):
#             result = json.loads(rec.Result())
#             print(result.get("text"))


# from datasets import load_dataset
# import json
# import pandas as pd

# # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ
# df = pd.read_csv("ccc/train.csv")

# print(df.head())


# # Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ intentÙ‡Ø§
# intents = {}



# for _, row in df.iterrows():
#     intent = row["intent"]
#     intent_name = row["intent_name"]
#     domain_name = row["domain_name"]
#     text = row["text"]
    

#     intents.setdefault(intent_name, []).append(domain_name)


# # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
# with open("test.json", "w", encoding="utf-8") as f:
#     json.dump(intents, f, indent=4, ensure_ascii=False)

# print(intents.columns)

# print("âœ… ÙØ§ÛŒÙ„ intents.json Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯!")


# import pandas as pd
# import json

# # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù¾Ø§Ø±Ú©Øª (Ø§Ú¯Ù‡ Ø¬Ø§ÛŒ Ø¯ÛŒÚ¯Ù‡ Ú¯Ø°Ø§Ø´ØªÛŒØŒ Ù…Ø³ÛŒØ± Ø±Ùˆ ØªØºÛŒÛŒØ± Ø¨Ø¯Ù‡)
# parquet_path = "models/train-00000-of-00001.parquet"

# # ÙØ§ÛŒÙ„ Ø±Ùˆ Ø¨Ø®ÙˆÙ†
# df = pd.read_parquet(parquet_path)

# # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù† Ú†Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ø¯Ø§Ø±ÛŒÙ…
# print("Columns:", df.columns)

# # Ø­Ø§Ù„Ø§ Ø³Ø§Ø®ØªØ§Ø± intentâ€ŒÙ‡Ø§ Ø±Ùˆ Ø¨Ø³Ø§Ø²ÛŒÙ…
# intents = {}

# for _, row in df.iterrows():
#     intent = row["intent"]
#     text = row["text"]
    

#     if intent not in intents:
#         intents[intent] = []

#     intents[intent].append(text)

# # Ø­Ø§Ù„Ø§ Ø³Ø§Ø®ØªØ§Ø± JSON Ù†Ù‡Ø§ÛŒÛŒ
# intent_data = {
#     "intents": []
# }

# for intent, patterns in intents.items():
#     intent_data["intents"].append({
#         "tag": intent,
#         "patterns": patterns,
#         "responses": ["..."]  # Ø¨Ø¹Ø¯Ø§Ù‹ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø±Ùˆ Ø¨Ø§ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ù¾Ø± Ú©Ù†ÛŒ
#     })

# # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ÙØ§ÛŒÙ„
# with open("models/intent.json", "w", encoding="utf-8") as f:
#     json.dump(intent_data, f, ensure_ascii=False, indent=4)

# print("âœ… ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„ intents.json Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

# from core.nlp import NLPProcessor

# nlp_processor = NLPProcessor()
# keywords = nlp_processor.extract_keywords("I'm working on an advanced AI assistant that talks and listens.")
# print(keywords)

# import pandas as pd
# import json

# # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV
# df = pd.read_csv("ccc/train.csv")

# # Ø³Ø§Ø®ØªØ§Ø± Ù†Ù‡Ø§ÛŒÛŒ ÙÙ‚Ø· Ø´Ø§Ù…Ù„ intent_name Ùˆ Ù„ÛŒØ³ØªÛŒ Ø§Ø² textâ€ŒÙ‡Ø§
# intents = {}

# for _, row in df.iterrows():
#     intent_name = row["intent_name"]
#     text = row["text"]

#     # Ø§Ú¯Ø± intent_name ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø§Ø¶Ø§ÙÙ‡â€ŒØ§Ø´ Ú©Ù†
#     if intent_name not in intents:
#         intents[intent_name] = []

#     # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† text Ø¨Ù‡ Ù„ÛŒØ³Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ intent_name
#     intents[intent_name].append(text)

# # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
# with open("models/intent.json", "w", encoding="utf-8") as f:
#     json.dump(intents, f, indent=4, ensure_ascii=False)

# print("âœ… ÙØ§ÛŒÙ„ intents.json ÙÙ‚Ø· Ø¨Ø§ intent_name Ùˆ text Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯!")

# import pandas as pd
# import json

# # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù…Ø­Ù„ÛŒ
# df = pd.read_csv("ccc/train.csv")

# # Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø§ÛŒ intent Ù‡Ø§
# intents = {}

# for _, row in df.iterrows():
#     # intent = row["intent"]
#     intent_name = row["intent_name"]
#     domain_name = row["domain_name"]
#     text = row["text"]
    
#     # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ intent Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡
#     if intent_name not in intents:
#         intents[intent_name] = {}

#     # if intent_name not in intents[intent_name]:
#     #     intents[intent_name][intent_name] = {}

#     if domain_name not in intents[intent_name]:
#         intents[intent_name][domain_name] = []

#     # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ø¨Ù‡ Ø¯Ø§Ù…ÛŒÙ† Ø®Ø§Øµ
#     intents[intent_name].append(text)

# # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ JSON
# with open("models/intent.json", "w", encoding="utf-8") as f:
#     json.dump(intents, f, indent=4, ensure_ascii=False)

# print("âœ… ÙØ§ÛŒÙ„ test.json Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯!")

# import pandas as pd

# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒØªØ§Ø³Øª
# intents = pd.read_csv("ccc/train.csv")


# # Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
# print("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:", intents.columns.tolist())

# # Ù†Ù…Ø§ÛŒØ´ ØªÙ…Ø§Ù… intent_nameâ€ŒÙ‡Ø§
# unique_intents = intents['intent_name'].unique()
# print("\nğŸ“Œ Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… intent_nameâ€ŒÙ‡Ø§:")
# for intent in unique_intents:
#     print(f"- {intent}")

# # Ù†Ù…Ø§ÛŒØ´ ØªÙ…Ø§Ù… domain_nameâ€ŒÙ‡Ø§
# unique_domains = intents['domain_name'].unique()
# print("\nğŸ“Œ Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… domain_nameâ€ŒÙ‡Ø§:")
# for domain in unique_domains:
#     print(f"- {domain}")




# test_intent.py
from intents.intent_classifier import IntentClassifier

model = IntentClassifier()

while True:
    text = input("You: ")
    if text.lower() in ["exit", "quit"]:
        break
    intent = model.predict(text)
    print(f"Detected intent: {intent}")
